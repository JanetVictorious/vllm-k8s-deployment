# vLLM on kubernetes

This repo deploys a vLLM OpenAI Inference Server on kubernetes.
